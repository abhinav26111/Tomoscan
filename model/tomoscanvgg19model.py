# -*- coding: utf-8 -*-
"""TomoScanVGG19model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sdoU5lEVoIkHkMOX34XdmNR6w3LfhgH3
"""

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES
# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.

import os
import sys
from tempfile import NamedTemporaryFile
from urllib.request import urlopen
from urllib.parse import unquote, urlparse
from urllib.error import HTTPError
from zipfile import ZipFile
import tarfile
import shutil

CHUNK_SIZE = 40960
DATA_SOURCE_MAPPING = 'tomato:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F259770%2F544347%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240412%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240412T170605Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Ddd84cae8540700b29dc58564b1e81d3d74d4bd2131383f3f5e2ee436d3f61cbbba5293b76b8c6f54030c1d2cd87855a5b43fbb64c3deca6ed85ad6de033032dfe99d37925141f460d60664e1a4ae0e14a4e542b7e65fca5d1db1f96926fe37e22edede339a8c8e4556c984e96c1644974756df0e7b8a21a49ac7e2b656c88448d334bdc0116ceb5730fa0fd0616cd0b8b846d2d8c562f1145c9d5d02e966c7c932cdc870e1e2cb6c840544735399916e338450b7f0e1575f21e5ba13622fd8832fe0917eba742b437d880e60caff8daae3b22fdb92c8b88f8c588fb011510afb707c808ea0a1dae377f8c118548191479c920ce8573d34e84b0beab291cc421f'

KAGGLE_INPUT_PATH='/kaggle/input'
KAGGLE_WORKING_PATH='/kaggle/working'
KAGGLE_SYMLINK='kaggle'

!umount /kaggle/input/ 2> /dev/null
shutil.rmtree('/kaggle/input', ignore_errors=True)
os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)
os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)

try:
  os.symlink(KAGGLE_INPUT_PATH, os.path.join("..", 'input'), target_is_directory=True)
except FileExistsError:
  pass
try:
  os.symlink(KAGGLE_WORKING_PATH, os.path.join("..", 'working'), target_is_directory=True)
except FileExistsError:
  pass

for data_source_mapping in DATA_SOURCE_MAPPING.split(','):
    directory, download_url_encoded = data_source_mapping.split(':')
    download_url = unquote(download_url_encoded)
    filename = urlparse(download_url).path
    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)
    try:
        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:
            total_length = fileres.headers['content-length']
            print(f'Downloading {directory}, {total_length} bytes compressed')
            dl = 0
            data = fileres.read(CHUNK_SIZE)
            while len(data) > 0:
                dl += len(data)
                tfile.write(data)
                done = int(50 * dl / int(total_length))
                sys.stdout.write(f"\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded")
                sys.stdout.flush()
                data = fileres.read(CHUNK_SIZE)
            if filename.endswith('.zip'):
              with ZipFile(tfile) as zfile:
                zfile.extractall(destination_path)
            else:
              with tarfile.open(tfile.name) as tarfile:
                tarfile.extractall(destination_path)
            print(f'\nDownloaded and uncompressed: {directory}')
    except HTTPError as e:
        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')
        continue
    except OSError as e:
        print(f'Failed to load {download_url} to path {destination_path}')
        continue

print('Data source import complete.')

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import os

path = "../input/tomato/New Plant Diseases Dataset(Augmented)"
os.listdir(path)

train_path = os.path.join(path, "train")
print(os.listdir(train_path))
print("*"*100)
test_path = os.path.join(path, "valid")
print(os.listdir(test_path))

from glob import glob
folders = glob("../input/tomato/New Plant Diseases Dataset(Augmented)/train/*")
folders

import matplotlib.pyplot as plt
plt.imshow(plt.imread("../input/tomato/New Plant Diseases Dataset(Augmented)/train/Tomato___Bacterial_spot/00416648-be6e-4bd4-bc8d-82f43f8a7240___GCREC_Bact.Sp 3110.JPG"))
plt.title("Bacterial Spot")

plt.imshow(plt.imread("../input/tomato/New Plant Diseases Dataset(Augmented)/train/Tomato___Early_blight/0034a551-9512-44e5-ba6c-827f85ecc688___RS_Erly.B 9432.JPG"))
plt.title("Early Blight")

plt.imshow(plt.imread("../input/tomato/New Plant Diseases Dataset(Augmented)/train/Tomato___Late_blight/0003faa8-4b27-4c65-bf42-6d9e352ca1a5___RS_Late.B 4946.JPG"))
plt.title("Late Blight")

train_dir = "../input/tomato/New Plant Diseases Dataset(Augmented)/train/"
val_dir = "../input/tomato/New Plant Diseases Dataset(Augmented)/val/"

class_names = sorted(os.listdir(train_dir))
class_names

class_dis = [len(os.listdir(train_dir + name)) for name in class_names]
class_dis

import plotly.express as px
fig = px.pie(names=class_names, values=class_dis, hole=0.3)
fig.update_layout({"title":{"text":"Distibution of classes", "x":0.50}})
fig.show()

from tensorflow.keras.layers import Input, Lambda, Dense, Flatten
from tensorflow.keras.models import Model
from tensorflow.keras.applications.inception_v3 import InceptionV3
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential

SIZE = [128, 128]

from tensorflow.keras.applications.vgg19 import VGG19

vg19 = VGG19(input_shape=SIZE + [3], weights="imagenet", include_top=False)

for layer in vg19.layers:
    layer.trainable = False

x = Flatten()(vg19.output)

prediction = Dense(len(folders), activation="softmax")(x)

modelvg = Model(inputs=vg19.input, outputs=prediction)

modelvg.summary()

modelvg.compile(loss="categorical_crossentropy", metrics=["accuracy"], optimizer="adam")

train_datagen_vg19 = ImageDataGenerator(rescale=1./255)

test_datagen_vg19 = ImageDataGenerator(rescale=1./255)

trainning_set_vg19 = train_datagen_vg19.flow_from_directory(train_path,
                                                 target_size=(128, 128),
                                                 batch_size=16,
                                                 class_mode="categorical", shuffle=True)

testing_set_vg19 = test_datagen_vg19.flow_from_directory(test_path,
                                                 target_size=(128, 128),
                                                 batch_size=16,
                                                 class_mode="categorical", shuffle=False)

import tensorflow as tf
callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)

r_vg19 = modelvg.fit_generator(trainning_set_vg19,
                       validation_data=testing_set_vg19,
                       epochs=100,
                       callbacks=[callback]
                       )

import matplotlib.pyplot as plt
accuracy = r_vg19.history['accuracy']
val_accuracy = r_vg19.history['val_accuracy']
loss = r_vg19.history['loss']
val_loss = r_vg19.history['val_loss']
epochs = range(len(accuracy))
plt.title("Training and Validation Accuracy")
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.plot(epochs, accuracy, "b", label="trainning accuracy")
plt.plot(epochs, val_accuracy, "r", label="validation accuracy")
plt.legend()
plt.show()

plt.title('Training and Validation Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.plot(epochs, loss, "b", label="trainning loss")
plt.plot(epochs, val_loss, "r", label="validation loss")
plt.legend()
plt.show()

test_img = plt.imread("../input/tomato/New Plant Diseases Dataset(Augmented)/train/Tomato___Bacterial_spot/00416648-be6e-4bd4-bc8d-82f43f8a7240___GCREC_Bact.Sp 3110.JPG")

plt.imshow(test_img)

modelvg.save("vgg_19tl.model")

import cv2
import tensorflow as tf
def prepare(filepath):
    img_array = cv2.imread(filepath, cv2.IMREAD_COLOR)
    img_array = img_array / 255
    new_array = cv2.resize(img_array, (128, 128))
    return new_array.reshape(-1, 128, 128, 3)

model = tf.keras.models.load_model("vgg_19tl.model")

class_dict = trainning_set_vg19.class_indices
class_dict

def prediction_cls(prediction):
    for key, clss in class_dict.items():
        if np.argmax(prediction) == clss:
            details = details_dict[key]
            return key, details

import numpy as np
details_dict = {
    'Tomato___Bacterial_spot': "The tomato chosen has Bacterial spot (Caused by Xanthomonas spp.). \nManagement: Use fertilizers low in nitrogen, as excessive nitrogen can encourage lush growth that is more susceptible to bacterial infections. Focus on potassium-rich fertilizers to help strengthen cell walls and improve disease resistance.",
    'Tomato___Early_blight':  "The tomato chosen has Early blight (Caused by the fungus Alternaria solani). \nManagement: Avoid excessive nitrogen and focus on balanced fertilization to support overall plant health.",
    'Tomato___Late_blight':"The tomato chosen has Late blight (Caused by the fungus Phytophthora infestans). \nManagement: Maintain balanced nutrition to support plant health and avoid excessive nitrogen, which can promote lush growth more susceptible to fungal infections.",
    'Tomato___Leaf_mould':"The tomato chosen has Leaf mold (Caused by the fungus Fulvia fulva). \nManagement: Balanced fertilization can help maintain plant vigor and resilience. Adequate potassium levels can improve disease resistance.",
    'Tomato___Septoria_leaf_spot' :"The tomato chosen has Septoria leaf spot (Caused by the fungus Septoria lycopersici). \nManagement: Balanced fertilization with adequate potassium levels can help improve disease resistance. Avoid excessive nitrogen, which can promote lush foliage more susceptible to fungal infections.",
    'Tomato___Spider_mites Two-spotted_spider_mite':"The tomato chosen has Two-spotted spider mite (Tetranychus urticae). \nManagement: While not a disease, maintaining proper fertilization can help keep plants healthy and better able to withstand pest infestations. Avoid over-fertilization, as this can attract mites.",
    'Tomato___Target_spot':"The tomato chosen has Target spot (Caused by the fungus Corynespora cassiicola). \nManagement: Maintain balanced nutrition to support plant health. Avoid excessive nitrogen, as it can promote lush foliage that is more susceptible to fungal diseases.",
    'Tomato___Tomato_Yellow_Leaf_Curl_Virus': "The tomato chosen has Yellow leaf curl virus (Caused by various Begomovirus species). \nManagement: Ensure the plant's nutritional needs are met with balanced fertilization to support its overall health and vigor.",
    'Tomato___Tomato_mosaic_virus': "The tomato chosen has Tomato mosaic virus (Caused by virus). \nManagement: Use a balanced fertilizer with moderate levels of nitrogen, phosphorus, and potassium to support overall plant health and vigor.",
    'Tomato___healthy':"The image of the tomato leaf chosen is healthy."

}

prediction = model.predict([prepare("../input/tomato/New Plant Diseases Dataset(Augmented)/valid/Tomato___healthy/0a334ae6-bea3-4453-b200-85e082794d56___GH_HL Leaf 310.1_flipTB.JPG")])[0]
predicted_class, details = prediction_cls(prediction)
print("Predicted class:", predicted_class)
print("Details:", details)

prediction = model.predict([prepare("../input/tomato/New Plant Diseases Dataset(Augmented)/valid/Tomato___Late_blight/005e3b43-9050-47da-9498-f9ecdcc703b3___RS_Late.B 5104.JPG")])
predicted_class, details = prediction_cls(prediction)
print("Predicted class:", predicted_class)
print("Details:", details)

prediction = model.predict([prepare("../input/tomato/New Plant Diseases Dataset(Augmented)/valid/Tomato___Early_blight/004cbe60-8ff9-4965-92df-e86694d5e9ba___RS_Erly.B 8253.JPG")])
predicted_class, details = prediction_cls(prediction)
print("Predicted class:", predicted_class)
print("Details:", details)

prediction = model.predict([prepare("../input/tomato/New Plant Diseases Dataset(Augmented)/valid/Tomato___Tomato_Yellow_Leaf_Curl_Virus/0383249b-008c-4e0b-b8ee-7eae08be99d3___YLCV_GCREC 2722.JPG")])
predicted_class, details = prediction_cls(prediction)
print("Predicted class:", predicted_class)
print("Details:", details)

from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix

train_loss, train_acc = modelvg.evaluate(trainning_set_vg19)
print("Training accuracy: {:.2f}%".format(train_acc * 100))

test_loss, test_acc = modelvg.evaluate(testing_set_vg19)
print("Test accuracy: {:.2f}%".format(test_acc * 100))

# Predict the classes of the test set
y_pred = modelvg.predict(testing_set_vg19)
y_pred_classes = np.argmax(y_pred, axis=1)

precision = precision_score(testing_set_vg19.classes, y_pred_classes, average='weighted')
recall = recall_score(testing_set_vg19.classes, y_pred_classes, average='weighted')
f1 = f1_score(testing_set_vg19.classes, y_pred_classes, average='weighted')
confusion = confusion_matrix(testing_set_vg19.classes, y_pred_classes)

# Print the results
print("Precision: {:.2f}%".format(precision * 100))
print("Recall: {:.2f}%".format(recall * 100))
print("F1 score: {:.2f}%".format(f1 * 100))
print("Confusion matrix:")
print(confusion)

!pip install tabulate

from tabulate import tabulate

# Calculate precision, recall, and F1 score for each class
class_precision = precision_score(testing_set_vg19.classes, y_pred_classes, average=None)
class_recall = recall_score(testing_set_vg19.classes, y_pred_classes, average=None)
class_f1 = f1_score(testing_set_vg19.classes, y_pred_classes, average=None)

# Create a list of lists to store the table data
table_data = [['Class', 'Precision', 'Recall', 'F1 score']]

# Add the class-wise metrics to the table data
for i in range(len(class_names)):
    table_data.append([class_names[i], f"{class_precision[i] * 100:.2f}", f"{class_recall[i] * 100:.2f}", f"{class_f1[i] * 100:.2f}"])

# Print the table
print("Class-wise Precision, Recall, and F1 score:")
print(tabulate(table_data, tablefmt='grid'))

import seaborn as sns
import matplotlib.pyplot as plt

# Calculate the confusion matrix
confusion = confusion_matrix(testing_set_vg19.classes, y_pred_classes)

# Plot the confusion matrix with colors
plt.figure(figsize=(10, 8))
sns.heatmap(confusion, annot=True, cmap='Blues', fmt='g')
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()

from sklearn.metrics import classification_report

# Print the classification report
print(classification_report(testing_set_vg19.classes, y_pred_classes, target_names=class_names))

# Save the model to a HDF5 file
modelvg.save('modelvg.h5')

# Save the model to a HDF5 file
modelvg.save('modelvg.keras')